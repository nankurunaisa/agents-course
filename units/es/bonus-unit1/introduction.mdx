# Introducci√≥n

![Bonus Unit 1 Thumbnail](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

Bienvenido a esta primera **Unidad Bonus**, donde aprender√°s a **hacer fine-tuning de un Modelo de Lenguaje Grande (LLM) para llamadas a funciones**.

En t√©rminos de LLMs, la llamada a funciones se est√° convirtiendo r√°pidamente en una t√©cnica *imprescindible*. 

La idea es que, en lugar de depender solo de enfoques basados en prompts como hicimos en la Unidad 1, la llamada a funciones entrena a tu modelo para **realizar acciones e interpretar observaciones durante la fase de entrenamiento**, haciendo tu IA m√°s robusta.

> **¬øCu√°ndo deber√≠a hacer esta Unidad Bonus?**
>
> Esta secci√≥n es **opcional** y es m√°s avanzada que la Unidad 1, as√≠ que no dudes en hacer esta unidad ahora o revisitarla cuando tu conocimiento haya mejorado gracias a este curso. 
>  
> Pero no te preocupes, esta Unidad Bonus est√° dise√±ada para tener toda la informaci√≥n que necesitas, as√≠ que te guiaremos a trav√©s de cada concepto fundamental del fine-tuning de un modelo para llamadas a funciones, incluso si a√∫n no has aprendido el funcionamiento interno del fine-tuning.

La mejor manera para que puedas seguir esta Unidad Bonus es:

1. Saber c√≥mo hacer Fine-Tuning de un LLM con Transformers, si no es el caso [revisa esto](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt).

2. Saber c√≥mo usar `SFTTrainer` para hacer fine-tuning de nuestro modelo, para aprender m√°s sobre esto [revisa esta documentaci√≥n](https://huggingface.co/learn/nlp-course/en/chapter11/1). 

---

## Lo que Aprender√°s

1. **Llamadas a Funciones**  
   C√≥mo los LLMs modernos estructuran sus conversaciones de manera efectiva permiti√©ndoles activar **Herramientas**.

2. **LoRA (Adaptaci√≥n de Bajo Rango)**  
   Un m√©todo de fine-tuning **ligero y eficiente** que reduce la sobrecarga computacional y de almacenamiento. LoRA hace que el entrenamiento de modelos grandes sea *m√°s r√°pido, econ√≥mico y f√°cil* de implementar.

3. **El Ciclo Pensamiento ‚Üí Acci√≥n ‚Üí Observaci√≥n** en modelos de Llamadas a Funciones  
   Un enfoque simple pero poderoso para estructurar c√≥mo tu modelo decide cu√°ndo (y c√≥mo) llamar funciones, rastrear pasos intermedios e interpretar los resultados de Herramientas o APIs externas.

4. **Nuevos Tokens Especiales**  
   Introduciremos **marcadores especiales** que ayudan al modelo a distinguir entre:
   - Razonamiento interno de "cadena de pensamiento"  
   - Llamadas a funciones salientes  
   - Respuestas que regresan de herramientas externas

---

Al final de esta unidad bonus, ser√°s capaz de:

- **Entender** el funcionamiento interno de las APIs cuando se trata de Herramientas.  
- **Hacer fine-tuning** de un modelo usando la t√©cnica LoRA.  
- **Implementar** y **modificar** el ciclo Pensamiento ‚Üí Acci√≥n ‚Üí Observaci√≥n para crear flujos de trabajo de Llamadas a funciones robustos y mantenibles.  
- **Dise√±ar y utilizar** tokens especiales para separar sin problemas el razonamiento interno del modelo de sus acciones externas.

Y **habr√°s hecho fine-tuning de tu propio modelo para realizar llamadas a funciones.** üî•

¬°Sumerj√°monos en las **llamadas a funciones**!
